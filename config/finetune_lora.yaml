# data config
dataset: xiaozeroone/Country-city-animals
subset: Corpus_narrative
max_token_length: 1024

# model config
model: meta-llama/Meta-Llama-3-8B
lora:
  r: 64
  use_rslora: true
  lora_alpha: 16
  lora_dropout: 0.0
  target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj
  task_type: CAUSAL_LM

# trainer config
batch_size: 16
accumulate_grad_batches: 1
max_epochs: 10
lr: 1e-4
lr_scheduler: linear
warmup_ratio: 0.1
scheduler: linear
gradient_clip_val: 1.0

# global config
save: save
seed: 1